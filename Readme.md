# Итоговый проект первого модуля Kafka

## Описание

Проект состоит из продюсера и двух консьюмеров для работы с Kafka-топиком `my-topic`. Один консьюмер использует pull-модель, а другой эмулирует push-модель.

## Структура проекта

- `docker-compose.yml` – настройка Kafka-кластера.
- `ProducerApp.java` – продюсер для отправки сообщений.
- `ConsumerPull.java` – консьюмер с pull-моделью.
- `ConsumerPush.java` – консьюмер с эмулированной push-моделью.
- `Message.java` – класс сообщения с сериализацией и десериализацией.
- `topic.txt` – команды для создания и описания топика.

## Запуск проекта

### 1. Запуск Kafka-кластера over Kraft:

```bash
docker-compose up -d
```

### 2. Создание топика:

Выполните команды из `topic.txt`:

```bash
docker exec -it kafka-0 /opt/bitnami/kafka/bin/kafka-topics.sh --create --topic my-topic --bootstrap-server kafka-0:9092,kafka-1:9092,kafka-2:9092 --partitions 3 --replication-factor 2

docker exec -it kafka-0 /opt/bitnami/kafka/bin/kafka-topics.sh --describe --topic my-topic --bootstrap-server kafka-0:9092
```

- `docker exec -it kafka-0` – выполнение команды внутри контейнера kafka-0 (имя жестко задано в docker-compose.yml).
- `/opt/bitnami/kafka/bin/kafka-topics.sh --create --topic my-topic` – создание топика с именем `my-topic`.
- `--bootstrap-server kafka-0:9092,kafka-1:9092,kafka-2:9092` – использование трёх брокеров (kafka-0, kafka-1, kafka-2) для установления начального соединения с кластером.
- `--partitions 3` – создание топика с 3 партициями.
- `--replication-factor 2` – установка фактора репликации равным 2.

После команды проверки должно отобразиться сообщение подобного вида:

```
Topic: my-topic TopicId: OVXBUJKOTASUNN7fuP9zlw PartitionCount: 3       ReplicationFactor: 2    Configs:                                                                                                                    
Topic: my-topic Partition: 0    Leader: 0       Replicas: 0,1   Isr: 1,0                                                                                                                                            
Topic: my-topic Partition: 1    Leader: 1       Replicas: 1,2   Isr: 1,2                                                                                                                                            
Topic: my-topic Partition: 2    Leader: 2       Replicas: 2,0   Isr: 0,2
```

### 3. Сборка приложения:

- Убедитесь, что в системе установлен Java 11+ и на предыдущем шаге успешно запущен кластер Kafka (можно через команду `docker ps`).
- Скомпилируйте проект:

```bash
mvn clean package
```

### 4. Запуск консьюмеров:

В отдельных терминалах запустите:

```bash
java -cp target/kafka-home-work-1.0-jar-with-dependencies.jar kafka.consumer.ConsumerPull
```

и

```bash
java -cp target/kafka-home-work-1.0-jar-with-dependencies.jar kafka.consumer.ConsumerPush
```

Если запуск в Windows, то рекомендуется вызвать `chcp 65001` для корректного вывода русскоязычных сообщений в консоль.

### 5. Запуск продюсера:

В отдельном терминале запустите:

```bash
java -cp target/kafka-home-work-1.0-jar-with-dependencies.jar kafka.producer.ProducerApp
```

Если запуск в Windows, то рекомендуется вызвать `chcp 65001` для корректного вывода русскоязычных сообщений в консоль.

## Проверка работы

- **Продюсер** выводит отправленные сообщения (автоматически сгенерированный JSON). Скорость вывода можно настраивать.
  ### Логика
    - `Автоматическая отправка сообщений` – Приложение генерирует и отправляет сообщения в Kafka-топик с настраиваемой скоростью (3 сообщения в секунду по умолчанию).
    - `Генерация данных` – Используется библиотека Faker для создания случайных данных (имена, адреса, компании, телефоны).
    - `Сериализация сообщений` – Данные преобразуются в JSON с помощью класса Message. При ошибке сериализации событие логируется.
    - `Отправка сообщений` – Сообщения отправляются в указанный топик с ключами для распределения по разделам. Логируется информация о результате отправки (успех или ошибка).
    - `Гарантии доставки` – Используются конфигурации acks=all и идемпотентность (idempotence=true) для предотвращения дублирования и обеспечения доставки.
    - `Обработка завершения работы` – Реализована корректная остановка продюсера и задач с помощью Shutdown Hook.
    - Подробные комментарии логики – в классе `src\main\java\kafka\producer\ProducerApp.java`.

- **ConsumerPull** выводит полученные сообщения и подтверждает смещения вручную.
  ### Логика
    - `Подключение к Kafka` – Консьюмер настраивается для работы с Kafka, используя параметры группы, смещений и чтения данных.
    - `Извлечение сообщений` – Сообщения получаются с помощью poll и обрабатываются по одному.
    - `Ретраи` – Реализована обработка сообщений с тремя попытками и задержкой между ними. В случае неудачи сообщение логируется.
    - `Ручной коммит` – После успешной обработки фиксируются смещения через commitSync.
    - `Логирование` – Вся обработка сообщений сопровождается логами в консоль.
    - Подробные комментарии логики – в классе `src\main\java\kafka\consumer\ConsumerPull.java`.

- **ConsumerPush** выводит полученные сообщения сразу после получения, используя автокоммит. П
  ### Логика
    - `Эмуляция push-модели` – Сообщения извлекаются с помощью poll и обрабатываются немедленно, что имитирует поведение push-модели.
    - `Автоматический коммит` – Включён автокоммит смещений для автоматизации управления состоянием обработки сообщений.
    - `Ретраи` – Реализована обработка сообщений с тремя попытками и задержкой между ними. Если количество попыток превышает лимит, сообщение ДОЛЖНО быть отправлено в DLQ иначе оно потеряется.
    - `Обработка в отдельном потоке` – Использование отдельного потока позволяет имитировать push-подход, при котором сообщения обрабатываются сразу по мере их поступления.
    - `Логирование` – Вся обработка сообщений сопровождается логами в консоль.
    - Подробные комментарии логики – в классе `src\main\java\kafka\consumer\ConsumerPush.java`.

- **Проверка ретраев (ручная)**
    Остановите приложение с продюсером, чтобы автоматически генерируемые сообщения не мешали тестированию
    В отдельных терминалах запустите:

    ```bash
    java -cp target/kafka-home-work-1.0-jar-with-dependencies.jar kafka.consumer.ConsumerPull
    ```

    ```bash
    java -cp target/kafka-home-work-1.0-jar-with-dependencies.jar kafka.consumer.ConsumerPush
    ```
    
    ```bash
    docker exec -it kafka-0 bash
    kafka-console-producer.sh --broker-list localhost:9092 --topic my-topic
    ```
    отправить сообщение со телом {"key": "test-key", "value": "test_retries"} , где значение value обязательно должно быть равно "test_retries", по которому есть условие проверки ретрая (ручной вызов RuntimeException в консьюмерах)
  

## Параметры конфигурации

### Producer:

- `BOOTSTRAP_SERVERS = "127.0.0.1:9094,127.0.0.1:9095,127.0.0.1:9096"` – адреса брокеров Kafka, к которым будет подключаться продюсер.
- `ACKS = "all"` – гарантирует, что сообщение записано на все реплики.
- `RETRIES = 3` – максимальное количество ретраев при сбоях.
- `IDEMPOTENCE = true` – включение идемпотентности для предотвращения дублирования сообщений.
- `RETRY_BACKOFF_MS = 1000` – задержка между повторными попытками отправки сообщений (в миллисекундах).
- `DELIVERY_TIMEOUT_MS = 120000` – таймаут доставки сообщения (в миллисекундах).
- `MESSAGES_PER_SECOND = 3` – количество сообщений, отправляемых в секунду.


### ConsumerPull:

- `BOOTSTRAP_SERVERS = "127.0.0.1:9094,127.0.0.1:9095,127.0.0.1:9096"` – адреса брокеров Kafka, к которым будет подключаться Consumer.
- `GROUP_ID = "consumer-pull-group"` – уникальный идентификатор группы консьюмеров.
- `OFFSET_RESET = "earliest"` – указывает, с какого места начинать чтение.
- `AUTO_COMMIT = false` – отключение автокоммита.
- `FETCH_MIN_BYTES = 1 * 1024 * 1024` – минимальный объём данных (в байтах), который должен быть доступен для чтения.
- `FETCH_MAX_WAIT_MS = 5000` – максимальное время ожидания новых данных.
- `POLL_TIMEOUT = Duration.ofMillis(5000)` – таймаут для метода `poll`.

### ConsumerPush:

- `BOOTSTRAP_SERVERS = "127.0.0.1:9094,127.0.0.1:9095,127.0.0.1:9096"` – адреса брокеров Kafka, к которым будет подключаться Consumer.
- `GROUP_ID = "consumer-push-group"` – уникальный идентификатор группы консьюмеров.
- `OFFSET_RESET = "earliest"` – указывает, с какого места начинать чтение.
- `AUTO_COMMIT = true` – включение автокоммита.
- `POLL_TIMEOUT = Duration.ofMillis(100)` – таймаут для метода `poll`.

## Зависимости

- Apache Kafka
- Jackson Databind
- Jackson Core
- SLF4J API
- Logback Classic
- Java Faker

